
### Predicting
@torch.no_grad()
def predict(model, loader, device) -> list:
    """
        model predict function
    """
    model.eval()
    all_preds = []
    for X, y in loader:
        X = X.to(device)
        y_ = model(X)
        all_preds.append(pd.DataFrame(y_.cpu().numpy(), index=y.index, columns=y.columns))
    return all_preds

def get_average_pred(all_preds, weights_halflife=None, ascending_weights=False):
    if weights_halflife is None:
        weights = [1] * len(all_preds)
    else:
        n = len(all_preds)
        if ascending_weights:
            lags = np.arange(n)[::-1]
        else:
            lags = np.arange(n)
        weights = 0.5 ** (lags / weights_halflife)
    
    weighted_values_list = []
    weight_counts_list = []
    for df, w in zip(all_preds, weights):
        weighted_values_list.append(df * w)
        weight_mask = df.notna().astype(float) * w
        weight_counts_list.append(weight_mask)

    concat_values = pd.concat(weighted_values_list)
    concat_weights = pd.concat(weight_counts_list)
    result_df = concat_values.groupby(level=0).sum() / concat_weights.groupby(level=0).sum()
    return result_df.sort_index()

def predict_all(raw_features, features, NN,
                startdate, enddate,
                predict_params={}, model=None):
    window_size = predict_params.get('window_size', 24)
    feature_df, target_df = prepare_data(raw_features, features, NN=NN,
                                         startdate=str_date_delta(startdate, -1-window_size//24),
                                         enddate=enddate, train=False)
    predict_loader = RollingDataLoader(
        feature_df, target_df,
        window_size=window_size,
        stride=predict_params.get('stride', 1),
        shuffle=False,
        train=False
    )
    all_preds = predict(model, predict_loader,
                        device=predict_params.get('device', torch.device('cuda' if torch.cuda.is_available() else 'cpu')))
    pred = get_average_pred(all_preds,
                            weights_halflife=predict_params.get('weights_halflife', None),
                            ascending_weights=predict_params.get('ascending_weights', False))
    # pred = pred ** 2
    # pred= np.exp(pred)  
    pred= pred.clip(lower=0, upper=1000)
    start_datetime, end_datetime = f'{startdate} 00:00:00', f'{enddate} 23:45:00'
    if predict_params.get('verbose', 1):
        pass
    return pred.loc[start_datetime: end_datetime]



### Constants
train_params = {
    'raw_features':['tp','ssrd','tcc','lcc','mcc','sp','sf','rhu','dni','d2','t2','u100','v100','win100_spd'
        # 'wind_speed_100m','wind_direction_100m','temperature_2m','shortwave_radiation_instant','cloud_cover','dew_point_2m','cloud_cover_low','cloud_cover_high','relative_humidity_2m','pressure_msl', 'precipitation'
        ], 

    'features': [
                #   'wind_gusts_10m_diff_12','wind_gusts_10m_diff'ï¼Œ
                # 'wind_speed_100m_diff_12','wind_speed_100m_diff'
                #  'temperature_ave','temperature_2m','precipitation','dew_point_2m','pressure_msl' ,'shortwave_radiation_instant','relative_humidity_2m',
            #  'hour','dayofweek','cloud_cover''la_speed_100m', 'lo_speed_100m','temperature_ave'
    'la_speed_cube','lo_speed_cube', 'wind_speed_100m_log','wind_cube'
             ,'tp','ssrd','tcc','sp','rhu','d2','t2','u100','v100' ,'hour','dayofweek'
             ],
    'rolling_train': True,
    'train_enddate_fix': '20260110',  # set this when rolling_train is False
    'train_enddate_gap':2,  # set this when rolling_train is True
    'train_lookback_dates': 24,

    'train_loader_params': {
        'window_size': 48,
        'stride': 1,
        'shuffle': True
    },
    'train_model_params': {
        'seed': 22,
        'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),
        'lr': 0.01,
        'weight_decay': 0,
        'l1_lambda': 0.05,# 0.001-0.1  
        'num_epochs': 10,
        'verbose': 1
    }
}
predict_params = {
    'window_size': 48,  # same as train_loader_params['window_size]
    'stride': 1,  # no larger than window_size,
    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),
    'weights_halflife': 1,
    'ascending_weights': True,
    'verbose': 1
}


### Main API
def prediction(date, tn=2):
    """
        main API
    """
    startdate = enddate = date.strftime('%Y%m%d')
    if train_params['rolling_train']:
        train_enddate = str_date_delta(enddate, -train_params['train_enddate_gap'])
        print(train_enddate)
    else:
        train_enddate = train_params['train_enddate_fix']
    model = train_model(raw_features=train_params['raw_features'], features=train_params['features'],
                        enddate=train_enddate, train_lookback_dates=train_params['train_lookback_dates'],
                        data_loader_params=train_params['train_loader_params'], model_params=train_params['train_model_params'])

    results = predict_all(raw_features=train_params['raw_features'], features=train_params['features'], NN=tn,
                          startdate=startdate, enddate=enddate,
                          predict_params=predict_params, model=model)
    return results

def _prediction_test(dates, tn=0, results_path='/home/myk/WorkSpace_myk/work/energy/traindata'):
    """
        main API for test
    """
    # assert not train_params['rolling_train']
    model = train_model(raw_features=train_params['raw_features'], features=train_params['features'],
                        enddate=train_params['train_enddate_fix'], train_lookback_dates=train_params['train_lookback_dates'],
                        data_loader_params=train_params['train_loader_params'], model_params=train_params['train_model_params'])
    results_list = []
    for date in dates:
        startdate = enddate = date.strftime('%Y%m%d')
        results = predict_all(raw_features=train_params['raw_features'], features=train_params['features'], NN=tn,
                          startdate=startdate, enddate=enddate,
                          predict_params=predict_params, model=model)
        results_list.append(results)
        print(f'{enddate} results predicted')
        print(results)
    pd.concat(results_list, axis=0).to_pickle(
        os.path.join(results_path, f"test_res_{dates[0].strftime('%Y%m%d')}_{dates[-1].strftime('%Y%m%d')}.pkl")
    )


if __name__ == '__main__':
    dates = pd.date_range(start='20260101', end='20260118', freq='d')
    # _prediction_test(dates, tn=2, results_path='/home/wyj/WorkSpace_wyj/shanxi/')
    
    results_list = []
    for date in dates:
        result = prediction(date, tn=2)
        results_list.append(result)
        print(f'{date.strftime("%Y%m%d")} results predicted')
        # concat to a single DataFrame and save
    results_list = pd.concat(results_list, axis=0)
  
    # res=prediction(pd.to_datetime('20260113'), tn=2)
    print(results_list)
